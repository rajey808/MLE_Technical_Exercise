{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title : Advanced Analytics MLE Technical Exercise <br>\n",
    "## Author : Yash Raje <br>\n",
    "Notes : Please change the input file directories for your local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "financialData = duckdb.read_csv(r'.\\business-financial-data-march-2024-csv.csv')\n",
    "employmentData = duckdb.read_csv(r'.\\machine-readable-business-employment-data-mar-2024-quarter.csv')\n",
    "regionalGDP = duckdb.read_csv(r'.\\regional-gross-domestic-product-year-ended-march-2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 <br>\n",
    "Anwser <br> \n",
    "Industry : Retail Trade <br>\n",
    "Filled Jobs (avg) : 194,054\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_q1 = \"\"\" \n",
    "WITH industries_after_2016 as (\n",
    "SELECT DISTINCT(Series_Title_2) as INDUSTRIES FROM financialData \n",
    "WHERE Series_title_1 = 'Salaries and wages' AND CAST(Period AS VARCHAR) NOT LIKE '2016%'\n",
    "),\n",
    "industries_in_2016 as (\n",
    "SELECT DISTINCT(Series_Title_2) as INDUSTRIES FROM financialData \n",
    "WHERE Series_title_1 = 'Salaries and wages' AND CAST(Period AS VARCHAR) LIKE '2016%'\n",
    "),\n",
    "filled_jobs as (\n",
    "SELECT CAST(AVG(Data_Value) AS INT) AS AVG_FILLED_JOBS, Series_title_2 AS INDUSTRIES FROM employmentData\n",
    "WHERE Series_title_1 = 'Filled jobs'\n",
    "AND \"Group\" = 'Industry by employment variable'\n",
    "AND Series_title_3 = 'Actual'\n",
    "GROUP BY INDUSTRIES\n",
    ")\n",
    "SELECT industries_after_2016.INDUSTRIES, filled_jobs.AVG_FILLED_JOBS AS \"FILLED JOBS (AVG)\" FROM industries_after_2016\n",
    "LEFT JOIN industries_in_2016 ON industries_after_2016.INDUSTRIES = industries_in_2016.INDUSTRIES\n",
    "JOIN filled_jobs ON industries_after_2016.INDUSTRIES = filled_jobs.INDUSTRIES\n",
    "WHERE industries_in_2016.INDUSTRIES IS NULL\n",
    "ORDER BY \"FILLED JOBS (AVG)\" DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result_q1 = duckdb.query(query_q1).fetchdf()\n",
    "print(result_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 <br>\n",
    "Answer <br>\n",
    "Industry : Wholesale Trade <br>\n",
    "Period : 2023.03 <br> Operating Income Sales : 38,810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_q2 = \"\"\"\n",
    "WITH operating_income_sales AS (\n",
    "SELECT Series_title_2 as INDUSTRY, Period AS PERIOD, CAST(Data_Value AS INT) AS \"OP INCOME SALES\" FROM financialData\n",
    "WHERE \"GROUP\" LIKE '%NZSIOC Level 2%'\n",
    "AND Series_title_1 = 'Sales (operating income)'\n",
    "AND Series_title_4 = 'Seasonally adjusted'\n",
    "ORDER BY Data_Value DESC\n",
    "Limit 2\n",
    ")\n",
    "SELECT * FROM operating_income_sales\n",
    "ORDER BY \"OP INCOME SALES\" ASC\n",
    "Limit 1\n",
    "\"\"\"\n",
    "\n",
    "result_q2 = duckdb.query(query_q2).fetchdf()\n",
    "print(result_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 <br>\n",
    "Assumption : Excluding 'Filled jobs (workplace location based)' <br>\n",
    "Answer <br>\n",
    "Territory : Auckland <br>\n",
    "Cumulative Jobs Filled : 34,995,011 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_q3 = \"\"\"\n",
    "WITH RECURSIVE territory_w_highest_avg_filled_jobs AS (\n",
    "SELECT AVG(Data_Value) AS AVG_DATA_VALUE, Series_title_2 FROM employmentData\n",
    "WHERE \"GROUP\" = 'Territorial authority by employment variable'\n",
    "AND Series_title_1 = 'Filled jobs'\n",
    "GROUP BY Series_title_2\n",
    "ORDER BY AVG_DATA_VALUE DESC\n",
    "LIMIT 1\n",
    "), \n",
    "filled_jobs AS (\n",
    "SELECT Period, Data_Value, employmentData.Series_title_2 AS TERRITORY\n",
    "FROM employmentData\n",
    "JOIN territory_w_highest_avg_filled_jobs ON employmentData.Series_title_2 = territory_w_highest_avg_filled_jobs.Series_title_2\n",
    "WHERE \"GROUP\" = 'Territorial authority by employment variable' AND Series_title_1 = 'Filled jobs'\n",
    "),\n",
    "cumalative_data AS (\n",
    "SELECT filled_jobs.Period, filled_jobs.Data_Value, Data_Value AS CUMULATIVE_DATA_VALUE, filled_jobs.TERRITORY FROM filled_jobs\n",
    "WHERE Period = (SELECT MIN(Period) FROM filled_jobs)\n",
    "UNION ALL\n",
    "SELECT filled_jobs.Period, filled_jobs.Data_Value, filled_jobs.Data_Value + cumalative_data.CUMULATIVE_DATA_VALUE AS CUMULATIVE_DATA_VALUE, filled_jobs.TERRITORY FROM filled_jobs\n",
    "JOIN cumalative_data ON filled_jobs.Period = (SELECT MIN(filled_jobs.Period) FROM filled_jobs WHERE filled_jobs.Period > cumalative_data.Period)\n",
    ")\n",
    "SELECT TERRITORY, CAST(CUMULATIVE_DATA_VALUE  AS INT) AS \"CUMALITVE FILLED JOBS\" FROM cumalative_data\n",
    "ORDER BY Period DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result_q3 = duckdb.query(query_q3).fetchdf()\n",
    "print(result_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "The specific methodology is dependent on the tool or pipeline but the concepts remain the same.\n",
    "Data warehousing tools (such as Snowflake) can help support auditing inputs. \n",
    "\n",
    "A feedback loop using a DataOps monitoring process could be used to monitor and improve a pipeline over time.\n",
    "One way this can be done is to pick up abnormalities (e.g. wrong data type, null or missing data) in the data and raise an alert.\n",
    "Another step in the process could also track the dataset sizes (e.g. row count) over time to check for consistent sizes in input data. \n",
    "E.g. if an input file has hourly KPI values for the past day, it is expected to have a consistent number of rows over time, any inconsistency can be flagged.\n",
    "\n",
    "For duplicates, a common usage in SQL is the \"DISTINCT\" keyword with the column names to retrieve only unique values.\n",
    "\n",
    "There are many methods we can use to check for incorrect datatypes. One such is the regex matching the incoming values in a field.\n",
    "Depending on the tool, there are type cast checking functions, e.g isNumeric function which can be used for this purpose.\n",
    "\n",
    "For missing date rows you can use mean imputation taking the other datetime values into account. \n",
    "I have used this method in my time series clustering dataset to add in missing datetime rows as each trend needed the same number of data points for the function to work.\n",
    "\n",
    "Similarly for null or missing values in a row, we can also use imputation (mean, 0 or any value imputation), or alternatively remove the entire row from the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "BNZ provides a range of products to their customers, including loan and finance products for its business customers. <br>\n",
    "I wanted to use a dataset which could provide useful insights to BNZ relating to the above. <br>\n",
    "\n",
    "After looking through the data, I decided to use the employment dataset (job numbers by region) and an additional dataset from the Stats NZ website called the GDP by region dataset.<br>\n",
    "My assumption and reasoning is that regions which have a higher Year-on-Year (YoY) growth rate for number of jobs filled provide an opportunity for BNZ to sell more financial loan products to new and growing businesses.<br>\n",
    "The GDP growth data could help assess the risks of issuing these loans to businesses in the different regions, ie. regions with higher GDP growth could be seen as safer investments. <br>\n",
    "\n",
    "I created a heatmap model to show the average YoY growth for GDP and average YoY growth for job numbers across regions in NZ.\n",
    "Results and insights discussed below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate YoY Growth\n",
    "\n",
    "def calc_YoY(df):\n",
    "    df['DIFFERENCE'] = 100*(df.groupby('REGION')['AVG_DATA_VALUE'].diff())/df['AVG_DATA_VALUE']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_filled_jobs = \"\"\"\n",
    "SELECT Substring(CAST(PERIOD AS VARCHAR),1,4) AS YEAR, AVG(Data_Value) AS AVG_DATA_VALUE, Series_title_2 AS REGION FROM employmentData\n",
    "WHERE \"Group\" = 'Region by employment variable'\n",
    "AND Series_title_1 = 'Filled jobs'\n",
    "AND Series_title_3 = 'Actual'\n",
    "GROUP BY YEAR, REGION\n",
    "ORDER BY REGION, YEAR\n",
    "\"\"\"\n",
    "result_filled_jobs = duckdb.query(query_filled_jobs).fetchdf()\n",
    "\n",
    "query_gdp = \"\"\"\n",
    "SELECT Substring(CAST(PERIOD AS VARCHAR),1,4) AS YEAR, AVG(Data_Value) AS AVG_DATA_VALUE, Series_title_2 AS REGION FROM regionalGDP\n",
    "GROUP BY YEAR, REGION\n",
    "ORDER BY REGION, YEAR\n",
    "\"\"\"\n",
    "result_gdp = duckdb.query(query_gdp).fetchdf()\n",
    "\n",
    "filled_jobs_YoY_growth = calc_YoY(result_filled_jobs)\n",
    "filled_jobs_YoY_growth_mean = filled_jobs_YoY_growth.groupby('REGION').mean().reset_index()\n",
    "\n",
    "### Combine Nelson and Tasman stats into one region to be consistent across both datasets\n",
    "df_tasman_nelson = filled_jobs_YoY_growth_mean[filled_jobs_YoY_growth_mean['REGION'].isin(['Tasman','Nelson'])]\n",
    "combined = {'REGION':'Tasman/Nelson', 'AVG_DATA_VALUE': df_tasman_nelson['AVG_DATA_VALUE'].sum(), 'DIFFERENCE':df_tasman_nelson['DIFFERENCE'].sum()}\n",
    "\n",
    "filled_jobs_YoY_growth_mean = filled_jobs_YoY_growth_mean.append(combined, ignore_index=True)\n",
    "filled_jobs_YoY_growth_mean = filled_jobs_YoY_growth_mean.rename(columns={'AVG_DATA_VALUE':'AVG_DATA_VALUE_JOBS', 'DIFFERENCE':'Jobs_YoY_Growth'})\n",
    "\n",
    "gdp_YoY_growth = calc_YoY(result_gdp)\n",
    "gdp_YoY_growth_mean = gdp_YoY_growth.groupby('REGION').mean().reset_index()\n",
    "gdp_YoY_growth_mean = gdp_YoY_growth_mean.rename(columns={'AVG_DATA_VALUE':'AVG_DATA_VALUE_GDP', 'DIFFERENCE':'GDP_YoY_Growth'})\n",
    "\n",
    "### Merge the two dataframes\n",
    "merged_df = pd.merge(filled_jobs_YoY_growth_mean, gdp_YoY_growth_mean, on='REGION', how='inner')\n",
    "merged_df = merged_df[['REGION','GDP_YoY_Growth','Jobs_YoY_Growth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary Statistics\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric' : ['YoY GDP Growth', 'YoY Jobs Growth'],\n",
    "    'Mean' : [merged_df['GDP_YoY_Growth'].mean(), merged_df['Jobs_YoY_Growth'].mean()],\n",
    "    'Std' : [merged_df['GDP_YoY_Growth'].std(), merged_df['Jobs_YoY_Growth'].std()]\n",
    "}).round(2)\n",
    "\n",
    "print(f'Summary Statistics Table\\n\\n{summary_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Heatmap to visualise the growths in filled jobs and GDP by region ###\n",
    "### Melt the DataFrame\n",
    "df_melted = merged_df.melt(id_vars=['REGION'], var_name='Metric', value_name='YoY_Growth')\n",
    "\n",
    "### Pivot the data\n",
    "pivot_table = df_melted.pivot(\"REGION\", \"Metric\", \"YoY_Growth\")\n",
    "\n",
    "### Create the heatmap\n",
    "sns.heatmap(pivot_table, annot=True, cmap=\"YlGn\")\n",
    "plt.title('Average YoY Growth for GDP and Jobs by Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can extract a couple of insights.<br>\n",
    "All regions have a similar YoY GDP growth (mean of 8 with standard deviation of only 0.45).<br>\n",
    "Though not all regions have a proportional increase in the YoY job numbers (mean of 2, but a much larger standard deviation of 0.83). <br> \n",
    "Supported by the summary statistics table above.<br>\n",
    "\n",
    "We can see that the Tasman/Nelson region has the highest YoY job numbers growth amongst the regions while still having similar GDP growth suggesting there are increasing job numbers in that region so BNZ could focus on selling more business loans in that area.\n",
    "The Northland region has a similar phenomenon.<br>\n",
    "In contrast the West Coast region has low job numbers growth but still stable GDP growth suggesting there are fewer opportunities for BNZ to sell business loan products in that region.<br>\n",
    "Due to the similar YoY GDP growth across most regions, loans in most regions can be thought of as being similarly safe.<br>\n",
    "\n",
    "For improvements or further insights, I would suggest adding another variable to slice the data further.<br>\n",
    "My thinking was creating a model for job numbers by industry and region, which could further help tailor buisness loans to specific industries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
